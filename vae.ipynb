{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d161fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1\n",
    "IMAGE_SHAPE = 784\n",
    "ENCODER_H1_SHAPE = 256\n",
    "ENCODER_H2_SHAPE = 128\n",
    "LATENT_SHAPE = 16\n",
    "DECODER_H1_SHAPE = 128\n",
    "DECODER_H2_SHAPE = 256\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.05\n",
    "ALPHA = 1.0\n",
    "BETA = 1.0\n",
    "LEAKY_RELU_ALPHA = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b841509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def dReLU(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def dlinear(x):\n",
    "    return np.ones_like(x)\n",
    "\n",
    "def leaky_ReLU(x):\n",
    "    return np.where(x > 0, x, x * LEAKY_RELU_ALPHA)\n",
    "\n",
    "def dleaky_ReLU(x):\n",
    "    return np.where(x > 0, 1, LEAKY_RELU_ALPHA)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def mse_loss(x, x_hat):\n",
    "    return np.mean(np.sum((x - x_hat)**2, axis=1))\n",
    "\n",
    "def dmse_loss(x, x_hat):\n",
    "    return -2 * (x - x_hat) / x.shape[0]\n",
    "\n",
    "def kl_error(mu, log_var):\n",
    "    return np.mean(-0.5 * np.sum(1 + log_var - mu**2 - np.exp(log_var), axis=1))\n",
    "\n",
    "def dkl_error_mu(mu, log_var): #L = -ELBO (sign flipped)\n",
    "    dmu = mu\n",
    "    return dmu / mu.shape[0]\n",
    "\n",
    "def dkl_error_logvar(mu, log_var): #L = -ELBO (sign flipped)\n",
    "    dlogvar = 0.5 * (np.exp(log_var) - 1)\n",
    "    return dlogvar / mu.shape[0]\n",
    "\n",
    "def one_hot(y, batch_size, output_size): #across a batch, y is a vector\n",
    "    out = np.zeros((batch_size, output_size))\n",
    "    out[range(batch_size), y.T] = 1 #numpy indexing trick\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, size, input_size, activation, dactivation):\n",
    "        assert size > 0, \"Size must be a positive integer\"\n",
    "        assert input_size > 0, \"Input size must be a positive integer\"\n",
    "        assert callable(activation), \"Activation must be a callable function\"\n",
    "        assert callable(dactivation), \"Derivative of activation must be a callable function\"\n",
    "\n",
    "        self.__size = size\n",
    "        self.__dactivation = dactivation\n",
    "        self.z = None\n",
    "        self.input_size = input_size\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "        self.values = None\n",
    "        self.dweights = None\n",
    "        self.dbiases = None\n",
    "        self.__activation = activation\n",
    "\n",
    "    def get_size(self):\n",
    "        return self.__size\n",
    "    \n",
    "    def get_activation(self):\n",
    "        return self.__activation\n",
    "    \n",
    "    def random_he_initialize(self):\n",
    "        rng = np.random.standard_normal\n",
    "        self.weights = rng((self.input_size, self.__size)) * np.sqrt(2 / self.input_size)\n",
    "        self.biases = np.zeros((1, self.__size))\n",
    "        return self.weights, self.biases\n",
    "\n",
    "    def forward_prop(self, input):\n",
    "        input = np.array(input)\n",
    "        self.z = input @ self.weights + self.biases\n",
    "        self.values = self.__activation(self.z)\n",
    "        return self.values\n",
    "    \n",
    "    def backward_prop(self, input, delta): # divide by batch size in loss derivative\n",
    "        delta = delta * self.__dactivation(self.z)\n",
    "        self.dweights = input.T @ delta\n",
    "        self.dbiases = np.sum(delta, axis=0, keepdims=True)\n",
    "        delta = delta @ self.weights.T\n",
    "        return delta\n",
    "    \n",
    "    def update_params(self, learning_rate):\n",
    "        self.weights -= learning_rate * self.dweights\n",
    "        self.biases -= learning_rate * self.dbiases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed8665f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Propagation Output:\n",
      "[[ 1.62422615  4.44398404  1.31657426  0.          0.60853643]\n",
      " [ 1.16132118 11.59654667  2.02690983  0.          3.99983222]]\n",
      "Backward Propagation Delta:\n",
      "[[ 0.97300276 -0.40349484  0.52814894]\n",
      " [ 0.19037182 -0.24447343  1.11470255]]\n",
      "Updated Weights:\n",
      "[[-1.17613501  1.33816703  0.24339975  0.64010651  1.47052587]\n",
      " [ 0.1961389  -0.02775546 -1.14403819  0.16103675 -0.19129237]\n",
      " [ 0.74469445  1.00177597  1.07441696 -0.83365821 -0.19380157]]\n",
      "Updated Biases:\n",
      "[[-0.006 -0.006 -0.006  0.    -0.006]]\n"
     ]
    }
   ],
   "source": [
    "#test layer class\n",
    "test_layer = Layer(5, 3, activation=ReLU, dactivation=dReLU)\n",
    "test_layer.random_he_initialize(seed=RANDOM_SEED)\n",
    "input = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "output = test_layer.forward_prop(input)\n",
    "print(\"Forward Propagation Output:\")\n",
    "print(output)\n",
    "delta = np.array([[0.1, 0.2, 0.3, 0.4, 0.5], [0.5, 0.4, 0.3, 0.2, 0.1]])\n",
    "backprop_delta = test_layer.backward_prop(input, delta)\n",
    "print(\"Backward Propagation Delta:\")\n",
    "print(backprop_delta)\n",
    "test_layer.update_params(learning_rate=0.01)\n",
    "print(\"Updated Weights:\")  \n",
    "print(test_layer.weights)\n",
    "print(\"Updated Biases:\")\n",
    "print(test_layer.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e9b6f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE: \n",
    "    def __init__(self):\n",
    "        self.encoder_h1 = Layer(ENCODER_H1_SHAPE, IMAGE_SHAPE, activation=leaky_ReLU, dactivation=dleaky_ReLU)\n",
    "        self.encoder_h2 = Layer(ENCODER_H2_SHAPE, ENCODER_H1_SHAPE, activation=leaky_ReLU, dactivation=dleaky_ReLU)\n",
    "        self.z_mu = Layer(LATENT_SHAPE, ENCODER_H2_SHAPE, activation=linear, dactivation=dlinear)\n",
    "        self.z_log_var = Layer(LATENT_SHAPE, ENCODER_H2_SHAPE, activation=linear, dactivation=dlinear)\n",
    "        self.decoder_h1 = Layer(DECODER_H1_SHAPE, LATENT_SHAPE, activation=leaky_ReLU, dactivation=dleaky_ReLU)\n",
    "        self.decoder_h2 = Layer(DECODER_H2_SHAPE, DECODER_H1_SHAPE, activation=leaky_ReLU, dactivation=dleaky_ReLU)\n",
    "        self.output_layer = Layer(IMAGE_SHAPE, DECODER_H2_SHAPE, activation=sigmoid, dactivation=dsigmoid)\n",
    "\n",
    "    def initialize_weights(self, seed=None):\n",
    "        if seed is not None: np.random.seed(seed)\n",
    "        self.encoder_h1.random_he_initialize(seed)\n",
    "        self.encoder_h2.random_he_initialize(seed)\n",
    "        self.z_mu.random_he_initialize(seed)\n",
    "        self.z_log_var.random_he_initialize(seed)\n",
    "        self.decoder_h1.random_he_initialize(seed)\n",
    "        self.decoder_h2.random_he_initialize(seed)\n",
    "        self.output_layer.random_he_initialize(seed)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h1 = self.encoder_h1.forward_prop(x)\n",
    "        h2 = self.encoder_h2.forward_prop(h1)\n",
    "        z_mu = self.z_mu.forward_prop(h2)\n",
    "        z_log_var = self.z_log_var.forward_prop(h2)\n",
    "        return z_mu, z_log_var\n",
    "    \n",
    "    def reparameterize(self, z_mu, z_log_var):\n",
    "        eps = np.random.normal(size=z_mu.shape)\n",
    "        z = z_mu + np.exp(0.5 * z_log_var) * eps\n",
    "        return eps, z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h1 = self.decoder_h1.forward_prop(z)\n",
    "        h2 = self.decoder_h2.forward_prop(h1)\n",
    "        reconstructed_x = self.output_layer.forward_prop(h2)\n",
    "        return reconstructed_x\n",
    "    \n",
    "    def compute_loss(self, x, z_mu, z_log_var, reconstructed_x, alpha=1.0, beta=1.0):\n",
    "        mse = mse_loss(x, reconstructed_x)\n",
    "        kl = kl_error(z_mu, z_log_var)\n",
    "        return (mse * alpha + kl * beta), mse, kl\n",
    "\n",
    "    def backprop(self, z_mu, z_log_var, z, reconstructed_x, x, eps, alpha=1.0, beta=1.0):\n",
    "        delta = dmse_loss(x, reconstructed_x) * alpha\n",
    "        delta = self.output_layer.backward_prop(self.decoder_h2.values, delta)\n",
    "        delta = self.decoder_h2.backward_prop(self.decoder_h1.values, delta)\n",
    "        delta = self.decoder_h1.backward_prop(z, delta)\n",
    "\n",
    "        dmu = delta.copy()\n",
    "        dlogvar = delta * eps * 0.5 * np.exp(0.5 * z_log_var)\n",
    "\n",
    "        dmu += dkl_error_mu(z_mu, z_log_var) * beta\n",
    "        dlogvar += dkl_error_logvar(z_mu, z_log_var) * beta\n",
    "\n",
    "        delta_z_mu = self.z_mu.backward_prop(self.encoder_h2.values, dmu)\n",
    "        delta_z_logvar = self.z_log_var.backward_prop(self.encoder_h2.values, dlogvar)\n",
    "        delta = delta_z_mu + delta_z_logvar\n",
    "        delta = self.encoder_h2.backward_prop(self.encoder_h1.values, delta)\n",
    "        delta = self.encoder_h1.backward_prop(x, delta)\n",
    "\n",
    "    def update_weights(self, learning_rate):\n",
    "        self.output_layer.update_params(learning_rate)\n",
    "        self.decoder_h2.update_params(learning_rate)\n",
    "        self.decoder_h1.update_params(learning_rate)\n",
    "        self.z_mu.update_params(learning_rate)\n",
    "        self.z_log_var.update_params(learning_rate)\n",
    "        self.encoder_h2.update_params(learning_rate)\n",
    "        self.encoder_h1.update_params(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6616d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = pd.read_csv(\".\\\\data\\\\fashion-mnist_train.csv\")\n",
    "raw_test_data = pd.read_csv(\".\\\\data\\\\fashion-mnist_test.csv\")\n",
    "\n",
    "train_data = np.array(raw_train_data)\n",
    "validation_data = np.array(raw_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bed08aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle training data\n",
    "perm = np.random.permutation(len(train_data))\n",
    "train_data = train_data[perm]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e17d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[:, 1:].astype('float64')\n",
    "x_train /= 255.0\n",
    "y_train = train_data[:, 0].astype('int64')\n",
    "\n",
    "x_val = validation_data[:, 1:].astype('float64')\n",
    "x_val /= 255.0\n",
    "y_val = validation_data[:, 0].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e8e8ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: (np.float64(8.313180433306847), np.float64(0.2602627753092968), np.float64(8.05291765799755))\n"
     ]
    }
   ],
   "source": [
    "#test VAE class\n",
    "vae = VAE()\n",
    "vae.initialize_weights(seed=RANDOM_SEED)\n",
    "z_mu, z_log_var = vae.encode(x_train[:BATCH_SIZE])\n",
    "eps, z = vae.reparameterize(z_mu, z_log_var)\n",
    "reconstructed_x = vae.decode(z)\n",
    "loss = vae.compute_loss(x_train[:BATCH_SIZE], z_mu, z_log_var, reconstructed_x, alpha=ALPHA, beta=BETA)\n",
    "print(\"Initial Loss:\", loss)\n",
    "vae.backprop(z_mu, z_log_var, z, reconstructed_x, x_train[:BATCH_SIZE], eps, alpha=ALPHA, beta=BETA)\n",
    "vae.update_weights(learning_rate=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9d80a204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 27.0164, MSE: 27.0164, KL: 95.1171\n",
      "Epoch 2/100, Loss: 21.4497, MSE: 21.1349, KL: 104.9101\n",
      "Epoch 3/100, Loss: 18.8264, MSE: 18.2924, KL: 89.0092\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m     reconstructed_x = vae.decode(z)\n\u001b[32m     11\u001b[39m     loss, mse, kl = vae.compute_loss(x_batch, z_mu, z_log_var, reconstructed_x, alpha=ALPHA, beta=beta)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[43mvae\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_log_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreconstructed_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43mALPHA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     vae.update_weights(learning_rate=LEARNING_RATE)\n\u001b[32m     14\u001b[39m beta = \u001b[38;5;28mmin\u001b[39m(\u001b[32m1\u001b[39m, beta + \u001b[32m0.003\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mVAE.backprop\u001b[39m\u001b[34m(self, z_mu, z_log_var, z, reconstructed_x, x, eps, alpha, beta)\u001b[39m\n\u001b[32m     47\u001b[39m delta = \u001b[38;5;28mself\u001b[39m.decoder_h2.backward_prop(\u001b[38;5;28mself\u001b[39m.decoder_h1.values, delta)\n\u001b[32m     48\u001b[39m delta = \u001b[38;5;28mself\u001b[39m.decoder_h1.backward_prop(z, delta)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m dmu = \u001b[43mdelta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m dlogvar = delta * eps * \u001b[32m0.5\u001b[39m * np.exp(\u001b[32m0.5\u001b[39m * z_log_var)\n\u001b[32m     53\u001b[39m dmu += dkl_error_mu(z_mu, z_log_var) * beta\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Initialize and train VAE\n",
    "vae = VAE()\n",
    "vae.initialize_weights(seed=RANDOM_SEED)\n",
    "beta = 0.0\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in range(0, x_train.shape[0], BATCH_SIZE):\n",
    "        x_batch = x_train[i:i+BATCH_SIZE]\n",
    "        z_mu, z_log_var = vae.encode(x_batch)\n",
    "        eps, z = vae.reparameterize(z_mu, z_log_var)\n",
    "        reconstructed_x = vae.decode(z)\n",
    "        loss, mse, kl = vae.compute_loss(x_batch, z_mu, z_log_var, reconstructed_x, alpha=ALPHA, beta=beta)\n",
    "        vae.backprop(z_mu, z_log_var, z, reconstructed_x, x_batch, eps, alpha=ALPHA, beta=beta)\n",
    "        vae.update_weights(learning_rate=LEARNING_RATE)\n",
    "    beta = min(1, beta + 0.003)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss:.4f}, MSE: {mse:.4f}, KL: {kl:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fca61a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize some reconstructed images\n",
    "num_images = 3\n",
    "test_images = x_val[:num_images]\n",
    "reconstructed_images = vae.decode(vae.reparameterize(*vae.encode(test_images))[1])\n",
    "fig, axes = plt.subplots(2, num_images, figsize=(20, 4))\n",
    "for i in range(num_images):\n",
    "    axes[0, i].imshow(test_images[i].reshape(28, 28), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].imshow(reconstructed_images[i].reshape(28, 28), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
