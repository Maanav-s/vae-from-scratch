{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d161fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2253b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1\n",
    "IMAGE_SHAPE = 784\n",
    "ENCODER_H1_SHAPE = 200\n",
    "ENCODER_H2_SHAPE = 100\n",
    "LATENT_SHAPE = 20\n",
    "DECODER_H1_SHAPE = 100\n",
    "DECODER_H2_SHAPE = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b841509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def dReLU(z):\n",
    "    return np.where(z > 0, 1, 0)\n",
    "\n",
    "def leaky_ReLU(z, alpha):\n",
    "    return np.where(z > 0, z, z * alpha)\n",
    "\n",
    "def dleaky_ReLU(z, alpha):\n",
    "    return np.where(z > 0, 1, alpha)\n",
    "\n",
    "def one_hot(y, batch_size, output_size): #across a batch, y is a vector\n",
    "    out = np.zeros((batch_size, output_size))\n",
    "    out[range(batch_size), y.T] = 1 #numpy indexing trick\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fa2fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, size, input_size, activation, dactivation):\n",
    "        assert size > 0, \"Size must be a positive integer\"\n",
    "        assert input_size > 0, \"Input size must be a positive integer\"\n",
    "        assert callable(activation), \"Activation must be a callable function\"\n",
    "        assert callable(dactivation), \"Derivative of activation must be a callable function\"\n",
    "\n",
    "        self.__size = size\n",
    "        self.__dactivation = dactivation\n",
    "        self.z = None\n",
    "        self.input_size = input_size\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "        self.values = None\n",
    "        self.dweights = None\n",
    "        self.dbiases = None\n",
    "        self.__activation = activation\n",
    "\n",
    "    def get_size(self):\n",
    "        return self.__size\n",
    "    \n",
    "    def get_activation(self):\n",
    "        return self.__activation\n",
    "    \n",
    "    def random_he_initialize(self, seed=None):\n",
    "        if seed is not None: np.random.seed(seed)\n",
    "        rng = np.random.standard_normal\n",
    "        self.weights = rng((self.input_size, self.__size)) * np.sqrt(2 / self.input_size)\n",
    "        self.biases = np.zeros((1, self.__size))\n",
    "        return self.weights, self.biases\n",
    "\n",
    "    def forward_prop(self, input):\n",
    "        input = np.array(input)\n",
    "        self.z = input @ self.weights + self.biases\n",
    "        self.values = self.__activation(self.z)\n",
    "        return self.values\n",
    "    \n",
    "    def backward_prop(self, input, delta): # do I need to divide by B here?\n",
    "        delta = delta * self.__dactivation(self.z)\n",
    "        self.dweights = input.T @ delta\n",
    "        self.dbiases = np.sum(delta, axis=0, keepdims=True)\n",
    "        delta = delta @ self.weights.T\n",
    "        return delta\n",
    "    \n",
    "    def update_params(self, learning_rate):\n",
    "        self.weights -= learning_rate * self.dweights\n",
    "        self.biases -= learning_rate * self.dbiases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8665f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Propagation Output:\n",
      "[[1.14929388 0.         0.         0.         3.07653887]\n",
      " [3.07193415 0.         0.         0.         7.36267243]]\n",
      "Backward Propagation Delta:\n",
      "[[ 0.48592843 -0.28972488  0.58224005]\n",
      " [ 0.73379645 -0.95996024  0.68947495]]\n",
      "Updated Weights:\n",
      "[[ 1.30527244 -0.49949702 -0.43125043 -0.87607521  0.69760237]\n",
      " [-1.90619848  1.42463284 -0.62152283  0.26049433 -0.21861006]\n",
      " [ 1.16080613 -1.68209785 -0.26325254 -0.31357907  0.90471887]]\n",
      "Updated Biases:\n",
      "[[-0.006  0.     0.     0.    -0.006]]\n"
     ]
    }
   ],
   "source": [
    "#test layer class\n",
    "test_layer = Layer(5, 3, activation=ReLU, dactivation=dReLU)\n",
    "test_layer.random_he_initialize(seed=RANDOM_SEED)\n",
    "input = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "output = test_layer.forward_prop(input)\n",
    "print(\"Forward Propagation Output:\")\n",
    "print(output)\n",
    "delta = np.array([[0.1, 0.2, 0.3, 0.4, 0.5], [0.5, 0.4, 0.3, 0.2, 0.1]])\n",
    "backprop_delta = test_layer.backward_prop(input, delta)\n",
    "print(\"Backward Propagation Delta:\")\n",
    "print(backprop_delta)\n",
    "test_layer.update_params(learning_rate=0.01)\n",
    "print(\"Updated Weights:\")  \n",
    "print(test_layer.weights)\n",
    "print(\"Updated Biases:\")\n",
    "print(test_layer.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6616d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = pd.read_csv(\".\\\\data\\\\fashion-mnist_train.csv\")\n",
    "raw_test_data = pd.read_csv(\".\\\\data\\\\fashion-mnist_test.csv\")\n",
    "\n",
    "train_data = np.array(raw_train_data)\n",
    "validation_data = np.array(raw_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed08aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle training data\n",
    "perm = np.random.permutation(len(train_data))\n",
    "train_data = train_data[perm]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e17d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[:, 1:].astype('float64')\n",
    "x_train /= 255.0\n",
    "y_train = train_data[:, 0].astype('int64')\n",
    "\n",
    "x_val = validation_data[:, 1:].astype('float64')\n",
    "x_val /= 255.0\n",
    "y_val = validation_data[:, 0].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8e8ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
